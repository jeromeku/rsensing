#!/usr/bin/env python
#******************************************************************************
#  Name:     classify_cv.py
#  Purpose:  supervised classification of multispectral images
#            with IPython parallelized cross-validation  
#  Usage:             
#    python classify_cv.py
# 
#  Copyright (c) 2015, Mort Canty
#    This program is free software; you can redistribute it and/or modify
#    it under the terms of the GNU General Public License as published by
#    the Free Software Foundation; either version 2 of the License, or
#    (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU General Public License for more details.
import auxil.supervisedclass as sc 
from osgeo import gdal, ogr, osr
import os, time, sys, getopt
from osgeo.gdalconst import GA_ReadOnly, GDT_Byte
from shapely.geometry import asPolygon, MultiPoint
import matplotlib.pyplot as plt 
import numpy as np
import shapefile
from IPython.parallel import Client


def crossvalidate((Gstrn,lstrn,Gstst,lstst,L,trainalg)):
    import auxil.supervisedclass as sc 
    if   trainalg == 1:
        classifier = sc.Maxlike(Gstrn,lstrn)
    elif trainalg == 2:
        classifier = sc.Ffnbp(Gstrn,lstrn,L)
    elif trainalg == 3:
        classifier = sc.Ffncg(Gstrn,lstrn,L)
    elif trainalg == 4:
        classifier = sc.Svm(Gstrn,lstrn)       
    if classifier.train():
        return classifier.test(Gstst,lstst)
    else:
        return None
 
def main():    
    usage = '''
Usage: 
---------------------------------------------------------
python %s  [-p bandPositions] [- a algorithm] [-L number of hidden neurons]   
[-P generate class probabilities image] filename trainShapefile

bandPositions is a list, e.g., -p [1,2,4]  

algorithm  1=MaxLike
           2=NNet(backprop)
           3=NNet(congrad)
           4=SVM

If the input file is named 

         path/filenbasename.ext then

The output classification file is named 

         path/filebasename_class.ext

the class probabilities output file is named

         path/filebasename_classprobs.ext
         
and the test results file is named

         path/filebasename_<classifier>.tst
--------------------------------------------------------''' %sys.argv[0]
    options, args = getopt.getopt(sys.argv[1:],'hnPp:a:L:')
    pos = None
    probs = False   
    L = 8
    graphics = True
    trainalg = 1
    for option, value in options:
        if option == '-h':
            print usage
            return
        elif option == '-p':
            pos = eval(value)
        elif option == '-n':
            graphics = False            
        elif option == '-a':
            trainalg = eval(value)
        elif option == '-L':
            L = eval(value)    
        elif option == '-P':
            probs = True                              
    if len(args) != 2: 
        print 'Incorrect number of arguments'
        print usage
        sys.exit(1)      
    if trainalg == 1:
        algorithm = 'MaxLike'
    elif trainalg == 2:
        algorithm = 'NNet(Backprop)'
    elif trainalg == 3:
        algorithm =  'NNet(Congrad)'
    elif trainalg == 4:
        algorithm = 'SVM'                     
    infile = args[0]  
    trnfile = args[1]    

#     algorithm = 'MaxLike'
#     infile = 'd:\python\zfl2015\imagery\may0107pca.tif'
#     trnfile = 'd:\python\zfl2015\imagery\\train.shp'
      
    gdal.AllRegister() 
    if infile:                   
        inDataset = gdal.Open(infile,GA_ReadOnly)
        cols = inDataset.RasterXSize
        rows = inDataset.RasterYSize    
        bands = inDataset.RasterCount
        projection = inDataset.GetProjection()
        geotransform = inDataset.GetGeoTransform()
        if geotransform is not None:
            gt = list(geotransform) 
        else:
            print 'No geotransform available'
            return       
        imsr = osr.SpatialReference()  
        imsr.ImportFromWkt(projection)    
    else:
        return  
    if pos is None: 
        pos = range(1,bands+1)
    N = len(pos)    
    rasterBands = [] 
    for b in pos:
        rasterBands.append(inDataset.GetRasterBand(b))    
         
#  output files
    path = os.path.dirname(infile)
    basename = os.path.basename(infile)
    root, ext = os.path.splitext(basename)
    outfile = '%s/%s_class%s'%(path,root,ext)  
    tstfile = '%s/%s_%s.tst'%(path,root,algorithm)            
    if (trainalg in (2,3,4)) and probs:
#      class probabilities file
        probfile = '%s/%s_classprobs%s'%(path,root,ext) 
    else:
        probfile = None     
    
    r = shapefile.Reader(trnfile)
    records = r.records()
    shapes = r.shapes()   
#  number of classes    
    K = 0
    for record in records:
        classid = int(record[1])
        if classid > K:
            K = classid
    K += 1             
#  es kann losgehen    
    print '========================='
    print 'supervised classification'
    print '========================='
    print time.asctime()    
    print 'image:     '+infile
    print 'training:  '+trnfile  
    print 'algorithm: '+algorithm             
#  loop through the polygons    
    Gs = [] # train observations
    ls = [] # class labels
    classnames = '{unclassified'
    classids = set()
    print 'reading training data...'   
    for record,shape in zip(records,shapes):
        boundary = np.array(shape.points)
        classname = record[0]
        classid = record[1]
        if classid not in classids:
            classnames += ',   '+ classname
        classids = classids | set(classid)
#      label for this ROI           
        l = [0 for i in range(K)]
        l[int(classid)] = 1.0        
#      transform points to pixel coords 
        boundary[:,0] -= gt[0]
        boundary[:,1] -= gt[3]       
        U = np.mat([[gt[1],gt[2]],[gt[4],gt[5]]])
        bdry = ( U.I * boundary.T ).T
        polygon = asPolygon(bdry)
        minx,miny,maxx,maxy = map(int,list(polygon.bounds))
        pts=[]
        for i in range(minx,maxx+1):
            for j in range(miny,maxy+1): 
                pts.append((i,j))             
        multipt =  MultiPoint(pts) 
        roi = np.array(multipt.intersection(polygon),dtype=np.int).tolist()
#      cut out the bounded image cube               
        cube = np.zeros((maxy-miny+1,maxx-minx+1,len(rasterBands)))
        k=0
        for band in rasterBands:
            cube[:,:,k] = band.ReadAsArray(minx,miny,maxx-minx+1,maxy-miny+1)
            k += 1
#      get the training vectors
        for (x,y) in roi:         
            Gs.append(cube[y-miny,x-minx,:])
            ls.append(l)   
        polygon = None        
    classnames += '}'
    m = len(ls)       
    print str(m) + ' training pixel vectors were read in' 
    Gs = np.array(Gs) 
    ls = np.array(ls)
#  stretch the pixel vectors to [-1,1] (for ffn)
    maxx = np.max(Gs,0)
    minx = np.min(Gs,0)
    for j in range(N):
        Gs[:,j] = 2*(Gs[:,j]-minx[j])/(maxx[j]-minx[j]) - 1.0   
#  random permutation of training data
    idx = np.random.permutation(m)
    Gs = Gs[idx,:] 
    ls = ls[idx,:]             
#  setup output datasets 
    driver = inDataset.GetDriver() 
    outDataset = driver.Create(outfile,cols,rows,1,GDT_Byte) 
    projection = inDataset.GetProjection()
    geotransform = inDataset.GetGeoTransform()
    if geotransform is not None:
        outDataset.SetGeoTransform(tuple(gt))
    if projection is not None:
        outDataset.SetProjection(projection) 
    outBand = outDataset.GetRasterBand(1) 
    if probfile:   
        probDataset = driver.Create(probfile,cols,rows,K,GDT_Byte) 
        if geotransform is not None:
            probDataset.SetGeoTransform(tuple(gt))
        if projection is not None:
            probDataset.SetProjection(projection)  
        probBands = [] 
        for k in range(K):
            probBands.append(probDataset.GetRasterBand(k+1))         
#  initialize classifier  
    if   trainalg == 1:
        classifier = sc.Maxlike(Gs,ls)
    elif trainalg == 2:
        classifier = sc.Ffnbp(Gs,ls,L)
    elif trainalg == 3:
        classifier = sc.Ffncg(Gs,ls,L)
    elif trainalg == 4:
        classifier = sc.Svm(Gs,ls)         
#  train it            
    print 'training on %i pixel vectors...' % np.shape(Gs)[0]
    start = time.time()
    result = classifier.train()
    print 'elapsed time %s' %str(time.time()-start) 
    if result:
        if (trainalg in [2,3]) and graphics:
            cost = np.log10(result)  
            ymax = np.max(cost)
            ymin = np.min(cost) 
            xmax = len(cost)      
            plt.plot(range(xmax),cost,'k')
            plt.axis([0,xmax,ymin-1,ymax])
            plt.title('Log(Cross entropy)')
            plt.xlabel('Epoch')   
            plt.show()
#      classify the image           
        print 'classifying...'
        start = time.time()
        tile = np.zeros((cols,N),dtype=np.float32)    
        for row in range(rows):
            for j in range(N):
                tile[:,j] = rasterBands[j].ReadAsArray(0,row,cols,1)
                tile[:,j] = 2*(tile[:,j]-minx[j])/(maxx[j]-minx[j]) - 1.0               
            cls, Ms = classifier.classify(tile)  
            outBand.WriteArray(np.reshape(cls,(1,cols)),0,row)
            if probfile:
                Ms = np.byte(Ms*255)
                for k in range(K):
                    probBands[k].WriteArray(np.reshape(Ms[k,:],(1,cols)),0,row)
        outBand.FlushCache()
        print 'elapsed time %s' %str(time.time()-start)
        outDataset = None
        inDataset = None      
        if probfile:
            for probBand in probBands:
                probBand.FlushCache() 
            probDataset = None
            print 'class probabilities written to: %s'%probfile   
        K =  ls.shape[1]+1                     
        print 'thematic map written to: %s'%outfile
    else:
        print 'an error occured' 
        return 
#  cross-validation
    start = time.time()
    rc = Client()   
    print 'submitting cross-validation to %i IPython engines'%len(rc)  
    m = np.shape(Gs)[0]
    traintest = []
    for i in range(50):
        sl = slice(i*m//50,(i+1)*m//50)
        traintest.append( (np.delete(Gs,sl,0),np.delete(ls,sl,0), \
                                     Gs[sl,:],ls[sl,:],L,trainalg) )
    v = rc[:]   
    v.execute('import auxil.supervisedclass as sc') 
    result = v.map(crossvalidate,traintest).get()   
    print 'parallel execution time: %s' %str(time.time()-start)      
    print 'misclassification rate: %f' %np.mean(result)
    print 'standard deviation:     %f' %np.std(result)         
   
if __name__ == '__main__':
    main()
